{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import numpy as np\n",
    "from src.CNN import CNN\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ticker = \"AAPL\"\n",
    "years = 40"
   ],
   "id": "aed732e8b9657a56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "end_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.date.today() - datetime.timedelta(days=years*365)).strftime(\"%Y-%m-%d\")"
   ],
   "id": "c6d62f46417fd19e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = yf.download(ticker, start=start_date, end=end_date)",
   "id": "a2223fbf0d082996",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EDA",
   "id": "bff99c5fc320e35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get sample of data\n",
   "id": "7573b69ca5228b8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head()",
   "id": "fc76f57828f9e20b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "### Shape of data",
   "id": "7bc4a56b4e10ab40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.shape",
   "id": "529d4fca152fff05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "### Get summary of data and check for nulls",
   "id": "977121c112c282fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check columns and data types\n",
    "print(data.info())\n",
    "\n",
    "# get summaries\n",
    "print(data.describe())\n",
    "\n",
    "# check for nulls\n",
    "print(data.isnull().sum())"
   ],
   "id": "68e753c27dffa226",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get X and Y",
   "id": "694838567df8ecd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data[\"Target\"] = data[\"Close\"].shift(-1) # target: next day closing price\n",
    "data.dropna(inplace=True) # remove one row with nan target"
   ],
   "id": "cfa0034a8b0de0de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_vars = ['Close', 'High', 'Low', 'Open']\n",
    "output_var = 'Target'\n",
    "X = data[input_vars]\n",
    "y = data[output_var]"
   ],
   "id": "e865f437e1585a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X",
   "id": "f42febfb6bff3527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y",
   "id": "879671ffc9ba7a98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data[input_vars] = scale(data[input_vars], axis=0)\n",
    "data_in = data[input_vars]\n",
    "data_out = data[output_var]"
   ],
   "id": "2330731632f4f458",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_in",
   "id": "bffcb40e4700570c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_out",
   "id": "1ecb4b4769d2327f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_time_series_windows(data, window_size=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data_in[i:i+window_size])  # past 30 days\n",
    "        y.append(data_out[i+window_size])    # target: next day's close price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "data_values = data[['Open', 'High', 'Low', 'Close', 'Volume']].values \n",
    "X, y = create_time_series_windows(data_values, window_size=30)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ],
   "id": "2ad9393f7a6ec38e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)",
   "id": "10773dcae56f76f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "1e3cae0e85768537",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Manully build dataloaders",
   "id": "e6da6a265fcd44eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train the model",
   "id": "a6eec325c27619be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_dim = 4\n",
    "n_embedding = 64 # how many embeddings to represent each token with\n",
    "n_layers = 6\n",
    "block_size = 30 # how many tokens in each \"block\"\n",
    "batch_size = 16\n",
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "lr = 1e-4\n",
    "n_epochs = 100"
   ],
   "id": "1914efee48208e56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn = CNN(input_dim, block_size, conv_layers=4)\n",
    "cnn.to(device)"
   ],
   "id": "49fc65d3badaf519",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# use MSE Loss for regression\n",
    "criterion = torch.nn.MSELoss()"
   ],
   "id": "e29a05c0f53f61b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optimizer = torch.optim.Adam(cnn.parameters(), lr=lr)",
   "id": "7f06bc968c641ce7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training the model\n",
    "for epoch in range(n_epochs):\n",
    "    cnn.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for data, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = cnn(data.to(device))\n",
    "        #print(outputs.shape)\n",
    "        #print(labels.shape)\n",
    "        loss = criterion(labels.to(device), outputs)\n",
    "        #print(\"Loss\",loss.item())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ],
   "id": "743240dc321d0a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    n_batches = len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            output = model(data.unsqueeze(0))\n",
    "            \n",
    "            mse = (output, labels)\n",
    "            total_loss += mse.item()\n",
    "            \n",
    "    avg_loss = total_loss/n_batches\n",
    "    return avg_loss"
   ],
   "id": "9b5f8e2d8664c203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "eval_model(cnn, test_dataset)",
   "id": "cbc564a3c3d3b68e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
